{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial for Splitting Datasets - Part 2\n",
    "\n",
    "The first part of this tutorial concerned with the general concept of splitting\n",
    "tabular data contained in pandas dataframes. In the second part, we would like\n",
    "to focus on the `Dataset` structure, which is provided by PyTorch as a\n",
    "measure for providing data to the neural network training procedure.\n",
    "\n",
    "|                  |                                                                                                                                                                                                                                                                  |\n",
    "|------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Requirements   \t | \t- Basic python skills                                                                                                                                                                                                                                           |\n",
    "| Learning Goals \t | \t- Understanding basics of a pandas dataframe <br/>- Concept of splitting data into multiple partitions <br/>- Various splitting strategies for dataframes. <br/>- Understanding cross-validation <br/>- Application of cross-validation in a practical use-case |\n",
    "| Limitations    \t | - The tutorial only handles pandas dataframes and a numpy array in the practical use-case.                                                                                                                                                                       |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import uuid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.649191233Z",
     "start_time": "2023-07-05T12:21:20.829535929Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Dataset Object\n",
    "\n",
    "Before we dive into the actual data splitting, we introduce the `Dataset` object in general.\n",
    "While there exists the possibility to directly create a dataset from an array (`TensorDataset`)\n",
    "or a directory filled with images (`ImageFolder` in `torchvision`), building a custom routine\n",
    "yields maximal flexibility and requires only a little setup.\n",
    "\n",
    "As shown in the code snippet below, creating a dataset requires the implementation of two\n",
    "functions. The most important one is `__getitem__`. The function will receive an `idx` starting\n",
    "from 0 and should return the training data corresponding to the index. The kind of return value\n",
    "is not fixed or limited in any case. Returned tensors would be batched automatically by the\n",
    "subsequent `Dataloader`, while more complex data types would require a custom collate function.\n",
    "However, this is an advanced topic and is not covered in this tutorial.\n",
    "\n",
    "The second function to implement is the `__len__` function, which should simply return the\n",
    "number of elements in the dataset, which is very helpful for the dataloader."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __len__(self) -> int:\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Any:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.654495485Z",
     "start_time": "2023-07-05T12:21:22.650070182Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To showcase the base functionality of a `Dataset`, we create an object that\n",
    "contains a list of 100 randomly generated strings as our dummy data.\n",
    "The `__len__` function simply returns the number of elements in our data list.\n",
    "The `__getitem__` function is tied to the indices of the list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        num_samples = 100\n",
    "        # This just generates a list of random strings\n",
    "        self.data = [uuid.uuid4().hex.upper()[0:6] for _ in range(num_samples)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> str:\n",
    "        return self.data[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.664673337Z",
     "start_time": "2023-07-05T12:21:22.653784876Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`__len__` and `__getitem__` belong to the group of *magic methods*. This implies\n",
    "that the keyword name of the function is reserved to work with another operator.\n",
    "In other words, when calling the `len` function on our dataset object, the\n",
    "`__len__` function is called internally.\n",
    "The `__getitem__` method is triggered by the bracket operator as it is usual in\n",
    "dictionaries or list accesses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 100\n",
      "Samples: 55AA9F FF1131 E73A84\n"
     ]
    }
   ],
   "source": [
    "ds = MyDataset()\n",
    "print(f'Number of samples in dataset: {len(ds)}')\n",
    "print('Samples:', ds[0], ds[42], ds[77])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.685728349Z",
     "start_time": "2023-07-05T12:21:22.667602842Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As shown above we can extract samples of our choice with the help of the `[]` operator.\n",
    "\n",
    "In the next steps we show some possibilities of splitting and organizing such a `Dataset`\n",
    "object. We make the differentiation between *internal* and *external* splitting.\n",
    "\n",
    "## Internal Splitting\n",
    "\n",
    "With interal splitting we refer to the idea of subsetting the dataset itself.\n",
    "An easy-to-use utility is hereby the `random_split` function, which is contained in PyTorch\n",
    "itself.\n",
    "This functions returns two instances of `Dataset`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in train dataset: 80\n",
      "Samples in test dataset: 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, test_ds = random_split(dataset=ds, lengths=(0.8, 0.2))\n",
    "\n",
    "print(f'Samples in train dataset: {len(train_ds)}')\n",
    "print(f'Samples in test dataset: {len(test_ds)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.769516222Z",
     "start_time": "2023-07-05T12:21:22.722959012Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, without setting a seed, the split is not reproducible.\n",
    "Everytime the function is called, the subsets contain different samples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 7A7510 A1500F 502CF2\n",
      "(1): EA7C5A 4F9C53 1CDDB2\n",
      "(2): 0EFBF5 96B26F 7A7510\n",
      "(3): 2C9FCA 0EFBF5 40B47A\n",
      "(4): EDE893 F55E7A DB333C\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(dataset=ds, lengths=(0.8, 0.2))\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.770178837Z",
     "start_time": "2023-07-05T12:21:22.723382318Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In PyTorch the preferred way of setting seeds is by using the `Generator` utility.\n",
    "This object keeps track of the random state and can be used to steer random behavior\n",
    "without setting a global context.\n",
    "\n",
    "For this, a `Generator` instance is created and we set our own seed with the\n",
    "`manual_seed` method.\n",
    "It is quite often that seeds are chosen to be some prominent numbers like `1337` or `42`.\n",
    "In contrast to this common practice, the documentation of the PyTorch generator recommends\n",
    "the following:\n",
    "\n",
    "*It is recommended to set a large seed, i.e. a number that has a good balance of 0 and 1 bits. Avoid having many 0 bits in the seed.*\n",
    "\n",
    "As shown in literature before, the choice of the seed can have a significant impact on your result.\n",
    "So it may be a good opportunity to use a large number."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 65DCCD F238AF 31DE5B\n",
      "(1): 65DCCD F238AF 31DE5B\n",
      "(2): 65DCCD F238AF 31DE5B\n",
      "(3): 65DCCD F238AF 31DE5B\n",
      "(4): 65DCCD F238AF 31DE5B\n"
     ]
    }
   ],
   "source": [
    "from torch import Generator\n",
    "\n",
    "for i in range(5):\n",
    "    gen = Generator().manual_seed(1337)\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.770653800Z",
     "start_time": "2023-07-05T12:21:22.723720178Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that each time when the split is done, we create a new instance of `Generator` with the same seed.\n",
    "If `gen` is called, its internal state progresses and invoking the split operation is based on different\n",
    "random states.\n",
    "\n",
    "As it may sound counterintuitive this is an expected behavior.\n",
    "In this way randomness within the loop is still given, but e.g. doing 5 different splits in a row itself\n",
    "is reproducible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 65DCCD F238AF 31DE5B\n",
      "(1): EE2A71 31DE5B 4784D9\n",
      "(2): 40B47A 2C9FCA 63CC29\n",
      "(3): 0EFBF5 EE2A71 EDE893\n",
      "(4): A1500F 2C9FCA 40B47A\n"
     ]
    }
   ],
   "source": [
    "gen = Generator().manual_seed(1337)\n",
    "\n",
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.771944248Z",
     "start_time": "2023-07-05T12:21:22.724031856Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If one only wants to instantiate the `Generator` object once and would like to have a reproducible\n",
    "random behaviour within the program, the current random state can be extracted using `get_state`.\n",
    "The saved state can then be established again by `set_state`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 65DCCD F238AF 31DE5B\n",
      "(1): 65DCCD F238AF 31DE5B\n",
      "(2): 65DCCD F238AF 31DE5B\n",
      "(3): 65DCCD F238AF 31DE5B\n",
      "(4): 65DCCD F238AF 31DE5B\n"
     ]
    }
   ],
   "source": [
    "gen = Generator().manual_seed(1337)\n",
    "gen_state = gen.get_state()\n",
    "\n",
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    gen.set_state(gen_state)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.772445431Z",
     "start_time": "2023-07-05T12:21:22.765106377Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our examples we only did a train and validation split.\n",
    "The random split function additionally does arbitrary splits, when a respective `lengths` sequence is provided.\n",
    "In our case, we can easily use this to do the previously discussed train, validation and test split."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(dataset=ds, lengths=(0.6, 0.2, 0.2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.772661281Z",
     "start_time": "2023-07-05T12:21:22.765432506Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check which samples are in the respective subset, the `indices` attribute helps to identify the index of the samples in the original `Dataset` object.\n",
    "These indices could be saved persistently, e.g. in a file, which in turn can be used to reconstruct the training and test splits or - in other words -\n",
    "make your experiments reproducible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 55, 91, 56, 96, 61, 81, 60, 68, 2, 5, 73, 19, 58, 27, 0, 71, 93, 12, 39, 51, 35, 32, 11, 90, 33, 22, 57, 77, 86, 24, 48, 78, 17, 42, 74, 29, 14, 67, 80, 54, 6, 72, 84, 76, 45, 37, 85, 44, 46, 65, 49, 15, 16, 10, 47, 97, 87, 98, 18]\n"
     ]
    }
   ],
   "source": [
    "train_idxs = train_ds.indices\n",
    "print(train_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.773066207Z",
     "start_time": "2023-07-05T12:21:22.765706131Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given a list of indices and the original dataset, the subset can be reconstructed using the `Subset` object:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_ds = Subset(dataset=ds, indices=train_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.921231134Z",
     "start_time": "2023-07-05T12:21:22.765924524Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While subsetting the full `Dataset` object is a possibility, it also has its limitations.\n",
    "Keeping in mind the first part of this series, there are more options to\n",
    "splitting and subsetting than pure randomization.\n",
    "If one would like to utilize other utilities like stratified splitting or cross-validation,\n",
    "a different method needs to be used.\n",
    "\n",
    "## External Splitting\n",
    "\n",
    "Alternatively, the dataset itself can be constructed by passing data from the outside.\n",
    "A trivial thing to do would be to split the data and keep a copy of every split.\n",
    "However, in most cases keeping multiple copies of your data is inefficient or\n",
    "infeasible (thinking of most computer vision datasets).\n",
    "\n",
    "A solution to this problem is by handling data access over keys.\n",
    "A key can be anything that uniquely identifies a data sample: An index in a pandas dataframe,\n",
    "a file path to an image, a patient id, etc.\n",
    "Using keys, the dataset object serves as a measure to provide and/or load data on demand\n",
    "without having multiple copies of it.\n",
    "This lightweight list of keys can also be utilized for cross-validation to determine\n",
    "different folds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, keys: List[str], *args, **kwargs) -> None:\n",
    "        # Set list of keys, that identify a datasample.\n",
    "        self.keys = keys\n",
    "\n",
    "    # Function that loads/provides a datasample given a key.\n",
    "    def load_item(self, key) -> Any:\n",
    "        pass\n",
    "\n",
    "    # The size of the dataset is the number of keys.\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Any:\n",
    "        # Given an index, return a keys.\n",
    "        key = self.keys[idx]\n",
    "        # Retrieve data sample from key.\n",
    "        return self.load_item(key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T12:21:22.938826657Z",
     "start_time": "2023-07-05T12:21:22.807962352Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
