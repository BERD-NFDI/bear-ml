{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial for Splitting Datasets - Part 2\n",
    "\n",
    "The first part of this tutorial concerned with the general concept of splitting\n",
    "tabular data contained in pandas dataframes. In the second part, we would like\n",
    "to focus on the `Dataset` structure, which is provided by PyTorch as a\n",
    "measure for providing data to the neural network training procedure.\n",
    "\n",
    "|                  |                                                                                                                                                                                                                                                                  |\n",
    "|------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Requirements   \t | \t- Basic python skills                                                                                                                                                                                                                                           |\n",
    "| Learning Goals \t | \t- Understanding basics of a pandas dataframe <br/>- Concept of splitting data into multiple partitions <br/>- Various splitting strategies for dataframes. <br/>- Understanding cross-validation <br/>- Application of cross-validation in a practical use-case |\n",
    "| Limitations    \t | - The tutorial only handles pandas dataframes and a numpy array in the practical use-case.                                                                                                                                                                       |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import uuid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.411946731Z",
     "start_time": "2023-05-19T10:59:17.587908611Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Dataset Object\n",
    "\n",
    "Before we dive into the actual data splitting, we introduce the `Dataset` object in general.\n",
    "While there exists the possibility to directly create a dataset from an array (`TensorDataset`)\n",
    "or a directory filled with images (`ImageFolder` in `torchvision`), building a custom routine\n",
    "yields maximal flexibility and requires only a little setup.\n",
    "\n",
    "As shown in the code snippet below, creating a dataset requires the implementation of two\n",
    "functions. The most important one is `__getitem__`. The function will receive an `idx` starting\n",
    "from 0 and should return the training data corresponding to the index. The kind of return value\n",
    "is not fixed or limited in any case. Returned tensors would be batched automatically by the\n",
    "subsequent `Dataloader`, while more complex data types would require a custom collate function.\n",
    "However, this is an advanced topic and is not covered in this tutorial.\n",
    "\n",
    "The second function to implement is the `__len__` function, which should simply return the\n",
    "number of elements in the dataset, which is very helpful for the dataloader."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __len__(self) -> int:\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Any:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.418648245Z",
     "start_time": "2023-05-19T10:59:19.415619644Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To showcase the base functionality of a `Dataset`, we create an object that\n",
    "contains a list of 100 randomly generated strings as our dummy data.\n",
    "The `__len__` function simply returns the number of elements in our data list.\n",
    "The `__getitem__` function is tied to the indices of the list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        num_samples = 100\n",
    "        # This just generates a list of random strings\n",
    "        self.data = [uuid.uuid4().hex.upper()[0:6] for _ in range(num_samples)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> str:\n",
    "        return self.data[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.425927096Z",
     "start_time": "2023-05-19T10:59:19.423226152Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`__len__` and `__getitem__` belong to the group of *magic methods*. This implies\n",
    "that the keyword name of the function is reserved to work with another operator.\n",
    "In other words, when calling the `len` function on our dataset object, the\n",
    "`__len__` function is called internally.\n",
    "The `__getitem__` method is triggered by the bracket operator as it is usual in\n",
    "dictionaries or list accesses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 100\n",
      "Samples: 9A6439 B6B39F 6D5DC2\n"
     ]
    }
   ],
   "source": [
    "ds = MyDataset()\n",
    "print(f'Number of samples in dataset: {len(ds)}')\n",
    "print('Samples:', ds[0], ds[42], ds[77])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.456593711Z",
     "start_time": "2023-05-19T10:59:19.429309123Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As shown above we can extract samples of our choice with the help of the `[]` operator.\n",
    "\n",
    "In the next steps we show some possibilities of splitting and organizing such a `Dataset`\n",
    "object. We make the differentiation between *internal* and *external* splitting.\n",
    "\n",
    "## Internal Splitting\n",
    "\n",
    "With interal splitting we refer to the idea of subsetting the dataset itself.\n",
    "An easy-to-use utility is hereby the `random_split` function, which is contained in PyTorch\n",
    "itself.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in train dataset: 80\n",
      "Samples in test dataset: 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, test_ds = random_split(dataset=ds, lengths=(0.8, 0.2))\n",
    "\n",
    "print(f'Samples in train dataset: {len(train_ds)}')\n",
    "print(f'Samples in test dataset: {len(test_ds)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.476408774Z",
     "start_time": "2023-05-19T10:59:19.442055212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 8F4CAF F8258E A9E40B\n",
      "(1): 7147C9 C1B6D4 0050D4\n",
      "(2): 7B30DC 8F4CAF 732D9A\n",
      "(3): A1C6C8 E6F0CE 768AD0\n",
      "(4): 0050D4 4B402F F3B2D3\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(dataset=ds, lengths=(0.8, 0.2))\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.539808467Z",
     "start_time": "2023-05-19T10:59:19.451139768Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 9D4892 A1C6C8 F5F7AA\n",
      "(1): 9D4892 A1C6C8 F5F7AA\n",
      "(2): 9D4892 A1C6C8 F5F7AA\n",
      "(3): 9D4892 A1C6C8 F5F7AA\n",
      "(4): 9D4892 A1C6C8 F5F7AA\n"
     ]
    }
   ],
   "source": [
    "from torch import Generator\n",
    "\n",
    "for i in range(5):\n",
    "    gen = Generator().manual_seed(1337)\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.559149070Z",
     "start_time": "2023-05-19T10:59:19.494582842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 9D4892 A1C6C8 F5F7AA\n",
      "(1): F4694A F5F7AA 55C342\n",
      "(2): DAB541 B7EF5B 1ED98E\n",
      "(3): 440303 F4694A 0C7EF7\n",
      "(4): EC4CB9 B7EF5B DAB541\n"
     ]
    }
   ],
   "source": [
    "gen = Generator().manual_seed(1337)\n",
    "\n",
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.559837352Z",
     "start_time": "2023-05-19T10:59:19.494947522Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): 9D4892 A1C6C8 F5F7AA\n",
      "(1): 9D4892 A1C6C8 F5F7AA\n",
      "(2): 9D4892 A1C6C8 F5F7AA\n",
      "(3): 9D4892 A1C6C8 F5F7AA\n",
      "(4): 9D4892 A1C6C8 F5F7AA\n"
     ]
    }
   ],
   "source": [
    "gen = Generator().manual_seed(1337)\n",
    "gen_state = gen.get_state()\n",
    "\n",
    "for i in range(5):\n",
    "    train_ds, test_ds = random_split(ds, (0.8, 0.2), generator=gen)\n",
    "    gen.set_state(gen_state)\n",
    "    print(f'({i}): {train_ds[0]} {train_ds[42]} {train_ds[77]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.560113260Z",
     "start_time": "2023-05-19T10:59:19.495268554Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(dataset=ds, lengths=(0.6, 0.2, 0.2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:59:19.560540248Z",
     "start_time": "2023-05-19T10:59:19.495489173Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 46, 24, 15, 95, 25, 28, 26, 17, 39, 9, 14, 11, 79, 56, 6, 59, 18, 3, 58, 83, 89, 74, 4, 43, 75, 80, 52, 60, 68, 65, 98, 38, 33, 86, 35, 47, 91, 22, 82, 21, 84, 61, 30, 70, 31, 20, 99, 8, 94, 12, 63, 36, 19, 73, 2, 66, 42, 77, 69]\n"
     ]
    }
   ],
   "source": [
    "train_idxs = train_ds.indices\n",
    "print(train_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T11:05:25.064676521Z",
     "start_time": "2023-05-19T11:05:25.061393442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_ds = Subset(dataset=ds, indices=train_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T11:05:26.363635868Z",
     "start_time": "2023-05-19T11:05:26.359779054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## External Splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, keys: List[str], root: str) -> None:\n",
    "        self.root = root\n",
    "        self.keys = keys\n",
    "\n",
    "    def load_item(self, key) -> Any:\n",
    "        pass\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Any:\n",
    "        key = self.keys[idx]\n",
    "        return self.load_item(key)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
